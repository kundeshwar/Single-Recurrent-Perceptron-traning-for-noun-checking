{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zitWX0WJLJTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def preprocess_data(data):\n",
        "    train_pos_tags = []\n",
        "    train_chunk_tags = []\n",
        "    train_tokens = []\n",
        "    for example in data:\n",
        "        tokens = example[\"tokens\"]\n",
        "        pos_tags = example[\"pos_tags\"]\n",
        "        chunk_tags = example[\"chunk_tags\"]\n",
        "        encoded_pos = pos_tags\n",
        "        train_tokens.append(tokens)\n",
        "        train_pos_tags.append(pos_tags)\n",
        "        train_chunk_tags.append(chunk_tags)\n",
        "    return train_tokens, train_pos_tags, train_chunk_tags\n",
        "\n",
        "# Function to load data from JSON file\n",
        "def load_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    tokens = data['tokens']\n",
        "    pos_tags = data['pos_tags']\n",
        "    chunk_tags = data['chunk_tags']\n",
        "    return tokens, pos_tags, chunk_tags\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function (sigmoid)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of sigmoid\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Padding function for input data\n",
        "def pad_input_data(data, max_length):\n",
        "    padded_data = np.zeros((len(data), max_length))\n",
        "    for i, seq in enumerate(data):\n",
        "        padded_data[i, :len(seq)] = seq\n",
        "    return padded_data\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "    correct_predictions = np.sum(true_labels == predicted_labels)\n",
        "    total_predictions = len(true_labels)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "s-0KCdDDWnKs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_single_recurrent_perceptron(X, Y, weights_input_hidden, weights_hidden_output, learning_rate=0.01, epochs=100):\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "        output = sigmoid(output_layer_input)\n",
        "        Y_shape = (Y.shape[0], output_dim)\n",
        "\n",
        "        # Reshape padded_train_chunk_tags to match the correct shape\n",
        "        Y = Y[:, :output_dim].reshape(Y_shape)\n",
        "        print(Y.shape)\n",
        "        # Backpropagation through time\n",
        "        output_error = Y - output\n",
        "        output_delta = output_error * sigmoid_derivative(output)\n",
        "\n",
        "        hidden_error = output_delta.dot(weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "        # Update weights\n",
        "        weights_hidden_output += hidden_layer_output.T.dot(output_delta) * learning_rate\n",
        "        weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
        "\n",
        "    return weights_input_hidden, weights_hidden_output\n",
        "\n",
        "\n",
        "\n",
        "# Load data\n",
        "# Load training data\n"
      ],
      "metadata": {
        "id": "h7eUsYpyLTLa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/train.jsonl', 'r') as train_file:\n",
        "    train_data = [json.loads(line) for line in train_file]\n",
        "# Determine maximum sequence length\n",
        "\n",
        "train_tokens, train_pos_tags, train_chunk_tags = preprocess_data(train_data)\n",
        "\n",
        "with open('/content/test.jsonl', 'r') as train_file:\n",
        "    test_data = [json.loads(line) for line in train_file]\n",
        "test_tokens, test_pos_tags, test_chunk_tags = preprocess_data(test_data)\n",
        "\n",
        "# Determine maximum sequence length\n",
        "max_seq_length = max(len(seq) for seq in train_pos_tags)\n",
        "\n",
        "# Padding input data\n",
        "padded_train_pos_tags = pad_input_data(train_pos_tags, max_seq_length)\n",
        "padded_train_chunk_tags = pad_input_data(train_chunk_tags, max_seq_length)\n",
        "\n"
      ],
      "metadata": {
        "id": "JUxlwB0gWxDL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters\n",
        "np.random.seed(42)\n",
        "input_dim = 4  # Number of POS tags\n",
        "hidden_dim = 5  # Dimension of hidden layer\n",
        "output_dim = 2  # Binary output for chunking\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "# Initialize weights\n",
        "weights_input_hidden = np.random.rand(padded_train_pos_tags.shape[1], hidden_dim)\n",
        "weights_hidden_output = np.random.rand(hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "KWwEfAtKWzd9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for train_index, val_index in kf.split(padded_train_pos_tags):\n",
        "    X_train_fold, X_val_fold = padded_train_pos_tags[train_index], padded_train_pos_tags[val_index]\n",
        "    Y_train_fold, Y_val_fold = padded_train_chunk_tags[train_index], padded_train_chunk_tags[val_index]\n",
        "    print(X_train_fold.shape)\n",
        "    print(Y_train_fold.shape)\n",
        "    # Train the single recurrent perceptron\n",
        "    weights_input_hidden_trained, weights_hidden_output_trained = train_single_recurrent_perceptron(\n",
        "        X_train_fold, Y_train_fold, weights_input_hidden, weights_hidden_output, learning_rate, epochs)\n",
        "\n",
        "    # Validate on validation set\n",
        "    hidden_layer_input_val = np.dot(X_val_fold, weights_input_hidden_trained)\n",
        "    hidden_layer_output_val = sigmoid(hidden_layer_input_val)\n",
        "    output_layer_input_val = np.dot(hidden_layer_output_val, weights_hidden_output_trained)\n",
        "    output_val = sigmoid(output_layer_input_val)\n",
        "\n",
        "    # Predicted chunk tags\n",
        "    predicted_chunk_tags_val = np.argmax(output_val, axis=1)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    accuracy_fold = calculate_accuracy(np.argmax(Y_val_fold, axis=1), predicted_chunk_tags_val)\n",
        "    fold_accuracies.append(accuracy_fold)\n",
        "\n",
        "# Report cross-validation results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cjtfMyqXLTNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross-validation accuracies:\", fold_accuracies)\n",
        "print(\"Mean cross-validation accuracy:\", np.mean(fold_accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s91i5mYuYfn2",
        "outputId": "b9ff36e0-8333-48a0-c825-d093cd117c9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracies: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "Mean cross-validation accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the single recurrent perceptron on full training data\n",
        "weights_input_hidden_trained, weights_hidden_output_trained = train_single_recurrent_perceptron(\n",
        "    padded_train_pos_tags, padded_train_chunk_tags, weights_input_hidden, weights_hidden_output, learning_rate, epochs)\n",
        "\n"
      ],
      "metadata": {
        "id": "csXfqbuGW5Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = max(len(seq) for seq in train_pos_tags)"
      ],
      "metadata": {
        "id": "nyPOz79KYzPW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding function for input data\n",
        "def pad_input_data(data, max_length):\n",
        "    padded_data = np.zeros((len(data), max_length))\n",
        "    for i, seq in enumerate(data):\n",
        "        padded_data[i, :min(len(seq), max_length)] = seq[:max_length]  # Adjusted to use min(len(seq), max_length)\n",
        "    return padded_data\n"
      ],
      "metadata": {
        "id": "t6mGgRHealyj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on test set\n",
        "# hidden_layer_input_test = np.dot(pad_input_data(test_pos_tags, max_seq_length), weights_input_hidden_trained)\n",
        "# hidden_layer_output_test = sigmoid(hidden_layer_input_test)\n",
        "# output_layer_input_test = np.dot(hidden_layer_output_test, weights_hidden_output_trained)\n",
        "# output_test = sigmoid(output_layer_input_test)\n",
        "# predicted_chunk_tags_test = np.argmax(output_test, axis=1)\n",
        "\n",
        "\n",
        "# Pad test data to match maximum sequence length\n",
        "padded_test_pos_tags = pad_input_data(test_pos_tags, max_seq_length)\n",
        "print(padded_test_pos_tags.shape)\n",
        "print(weights_input_hidden_trained.shape)\n",
        "# Test on test set\n",
        "hidden_layer_input_test = np.dot(padded_test_pos_tags, weights_input_hidden_trained)\n",
        "hidden_layer_output_test = sigmoid(hidden_layer_input_test)\n",
        "output_layer_input_test = np.dot(hidden_layer_output_test, weights_hidden_output_trained)\n",
        "output_test = sigmoid(output_layer_input_test)\n",
        "predicted_chunk_tags_test = np.argmax(output_test, axis=1)\n"
      ],
      "metadata": {
        "id": "VY4lwUoALTQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47932afb-3adf-4616-af0a-3e3afee1fc97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3453, 113)\n",
            "(113, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_input_hidden_trained_transposed = weights_input_hidden_trained.T"
      ],
      "metadata": {
        "id": "ku1a3sFXaWA_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_input_hidden_trained_transposed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLkY8nJnaYBQ",
        "outputId": "45ccae2e-15b2-4716-d30e-1537e1d888e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 113)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on test set\n",
        "accuracy_test = calculate_accuracy(np.argmax(pad_input_data(test_chunk_tags, max_seq_length), axis=1), predicted_chunk_tags_test)\n",
        "print(\"Accuracy on test set:\", accuracy_test)\n",
        "\n",
        "# Error cases and analysis\n",
        "error_indices = np.where(predicted_chunk_tags_test != np.argmax(pad_input_data(test_chunk_tags, max_seq_length), axis=1))[0]\n",
        "print(\"Number of error cases:\", len(error_indices))\n",
        "print(\"Error indices:\", error_indices)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qt4aj7XWLTTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0295be-10e6-46a3-c941-dc1563dfa341"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 1.0\n",
            "Number of error cases: 0\n",
            "Error indices: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report model weights\n",
        "print(\"Model weights - Input to Hidden layer:\")\n",
        "print(weights_input_hidden_trained)\n",
        "print(\"Model weights - Hidden to Output layer:\")\n",
        "print(weights_hidden_output_trained)\n"
      ],
      "metadata": {
        "id": "AlDMW6fSLTW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate inequalities for model weights\n",
        "inequality1 = np.sum(weights_input_hidden_trained[:, 1:]) > np.sum(weights_input_hidden_trained[:, 0])\n",
        "inequality2 = np.sum(weights_hidden_output_trained[1:, :]) > np.sum(weights_hidden_output_trained[0, :])\n",
        "print(\"Inequality 1:\", inequality1)\n",
        "print(\"Inequality 2:\", inequality2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462NIxFxbbeB",
        "outputId": "bf99d8d3-040d-425c-ff12-8d34da1e1152"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inequality 1: True\n",
            "Inequality 2: False\n"
          ]
        }
      ]
    }
  ]
}